{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Visualization - GradCAM and Feature Analysis\n",
    "\n",
    "This notebook visualizes what the ConvNeXt model learns using GradCAM and feature embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "\n",
    "from src.model import ConvNeXtPrecursorModel\n",
    "from src.inference import PrecursorPredictor\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model\n",
    "model = ConvNeXtPrecursorModel.load_pretrained('../models/convnext_loeo_best.pth')\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GradCAM Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        \n",
    "        target_layer.register_forward_hook(self.save_activation)\n",
    "        target_layer.register_backward_hook(self.save_gradient)\n",
    "    \n",
    "    def save_activation(self, module, input, output):\n",
    "        self.activations = output.detach()\n",
    "    \n",
    "    def save_gradient(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0].detach()\n",
    "    \n",
    "    def generate(self, input_tensor, target_class=None):\n",
    "        self.model.model.eval()\n",
    "        output = self.model.model(input_tensor)\n",
    "        \n",
    "        if target_class is None:\n",
    "            target_class = output[0].argmax().item()\n",
    "        \n",
    "        self.model.model.zero_grad()\n",
    "        output[0][0, target_class].backward()\n",
    "        \n",
    "        weights = self.gradients.mean(dim=(2, 3), keepdim=True)\n",
    "        cam = (weights * self.activations).sum(dim=1, keepdim=True)\n",
    "        cam = torch.relu(cam)\n",
    "        cam = cam - cam.min()\n",
    "        cam = cam / cam.max()\n",
    "        \n",
    "        return cam.squeeze().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_gradcam(image_path, model, save_path=None):\n",
    "    # Load and preprocess image\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    input_tensor = transform(img).unsqueeze(0)\n",
    "    \n",
    "    # Get prediction\n",
    "    result = model.predict(input_tensor)\n",
    "    \n",
    "    # Generate GradCAM\n",
    "    target_layer = model.model.backbone.features[-1]\n",
    "    gradcam = GradCAM(model, target_layer)\n",
    "    cam = gradcam.generate(input_tensor)\n",
    "    \n",
    "    # Resize CAM to image size\n",
    "    cam_resized = cv2.resize(cam, (224, 224))\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0].imshow(img.resize((224, 224)))\n",
    "    axes[0].set_title('Original Spectrogram')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # GradCAM heatmap\n",
    "    axes[1].imshow(cam_resized, cmap='jet')\n",
    "    axes[1].set_title('GradCAM Heatmap')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Overlay\n",
    "    img_array = np.array(img.resize((224, 224))) / 255.0\n",
    "    heatmap = plt.cm.jet(cam_resized)[:, :, :3]\n",
    "    overlay = 0.6 * img_array + 0.4 * heatmap\n",
    "    axes[2].imshow(overlay)\n",
    "    axes[2].set_title(f'Overlay\\nMag: {result[\"magnitude_class\"]} ({result[\"magnitude_prob\"]:.1%})\\nAzi: {result[\"azimuth_class\"]} ({result[\"azimuth_prob\"]:.1%})')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "# visualize_gradcam('../data/spectrograms/sample.png', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Embedding Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def visualize_embeddings(model, dataloader, method='tsne'):\n",
    "    \"\"\"Visualize feature embeddings using t-SNE or PCA\"\"\"\n",
    "    model.model.eval()\n",
    "    \n",
    "    features = []\n",
    "    mag_labels = []\n",
    "    azi_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, mag, azi in dataloader:\n",
    "            feat = model.model.get_features(images.to(model.device))\n",
    "            if feat.dim() == 4:\n",
    "                feat = feat.flatten(1)\n",
    "            features.append(feat.cpu().numpy())\n",
    "            mag_labels.extend(mag.numpy())\n",
    "            azi_labels.extend(azi.numpy())\n",
    "    \n",
    "    features = np.vstack(features)\n",
    "    \n",
    "    # Dimensionality reduction\n",
    "    if method == 'tsne':\n",
    "        reducer = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "    else:\n",
    "        reducer = PCA(n_components=2)\n",
    "    \n",
    "    embeddings = reducer.fit_transform(features)\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    scatter1 = axes[0].scatter(embeddings[:, 0], embeddings[:, 1], \n",
    "                               c=mag_labels, cmap='viridis', alpha=0.7)\n",
    "    axes[0].set_title('Feature Embeddings (Magnitude)')\n",
    "    plt.colorbar(scatter1, ax=axes[0])\n",
    "    \n",
    "    scatter2 = axes[1].scatter(embeddings[:, 0], embeddings[:, 1], \n",
    "                               c=azi_labels, cmap='tab10', alpha=0.7)\n",
    "    axes[1].set_title('Feature Embeddings (Azimuth)')\n",
    "    plt.colorbar(scatter2, ax=axes[1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage (requires dataloader)\n",
    "# visualize_embeddings(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
